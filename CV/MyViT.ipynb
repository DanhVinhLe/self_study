{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Unzip dataset on Kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:36:05.276463Z","iopub.status.busy":"2024-03-11T16:36:05.276033Z","iopub.status.idle":"2024-03-11T16:36:11.622946Z","shell.execute_reply":"2024-03-11T16:36:11.621990Z","shell.execute_reply.started":"2024-03-11T16:36:05.276418Z"},"trusted":true},"outputs":[],"source":["import os\n","import zipfile \n","local_zip = '/kaggle/working/archive (2).zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/kaggle/working')\n","zip_ref.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:37:00.360833Z","iopub.status.busy":"2024-03-11T16:37:00.359896Z","iopub.status.idle":"2024-03-11T16:37:13.970951Z","shell.execute_reply":"2024-03-11T16:37:13.969844Z","shell.execute_reply.started":"2024-03-11T16:37:00.360793Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n","Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n"]}],"source":["!pip install einops"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:42:00.233256Z","iopub.status.busy":"2024-03-11T16:42:00.232832Z","iopub.status.idle":"2024-03-11T16:42:00.238990Z","shell.execute_reply":"2024-03-11T16:42:00.237885Z","shell.execute_reply.started":"2024-03-11T16:42:00.233223Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import einops\n","import torchvision\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:38:23.143109Z","iopub.status.busy":"2024-03-11T16:38:23.142726Z","iopub.status.idle":"2024-03-11T16:38:23.151603Z","shell.execute_reply":"2024-03-11T16:38:23.150535Z","shell.execute_reply.started":"2024-03-11T16:38:23.143079Z"},"trusted":true},"outputs":[],"source":["def get_device():\n","    if torch.cuda.is_available():\n","        return torch.device(\"cuda\")\n","    return torch.device(\"cpu\")\n","\n","def to_device(data,device):\n","    if isinstance(data,(list,tuple)):\n","        return [to_device(x,device) for x in data]\n","    return data.to(device,non_blocking=True)\n","\n","\n","class ToDeviceLoader:\n","    def __init__(self,data,device):\n","        self.data = data\n","        self.device = device\n","\n","    def __iter__(self):\n","        for batch in self.data:\n","            yield to_device(batch,self.device)\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"markdown","metadata":{},"source":["# Load, preprocess data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:38:50.744690Z","iopub.status.busy":"2024-03-11T16:38:50.743513Z","iopub.status.idle":"2024-03-11T16:38:50.748974Z","shell.execute_reply":"2024-03-11T16:38:50.747902Z","shell.execute_reply.started":"2024-03-11T16:38:50.744650Z"},"trusted":true},"outputs":[],"source":["test_path = '/kaggle/working/seg_test'\n","train_path = '/kaggle/working/seg_train'"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:39:16.733652Z","iopub.status.busy":"2024-03-11T16:39:16.732951Z","iopub.status.idle":"2024-03-11T16:39:16.739545Z","shell.execute_reply":"2024-03-11T16:39:16.738524Z","shell.execute_reply.started":"2024-03-11T16:39:16.733618Z"},"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((128,128)),\n","    transforms.ToTensor(),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((128,128)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:39:31.669826Z","iopub.status.busy":"2024-03-11T16:39:31.669115Z","iopub.status.idle":"2024-03-11T16:39:31.764789Z","shell.execute_reply":"2024-03-11T16:39:31.763772Z","shell.execute_reply.started":"2024-03-11T16:39:31.669790Z"},"trusted":true},"outputs":[],"source":["train_dataset = datasets.ImageFolder(root= train_path, transform= train_transform)\n","test_dataset = datasets.ImageFolder(root = test_path, transform= test_transform)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:39:44.081782Z","iopub.status.busy":"2024-03-11T16:39:44.081302Z","iopub.status.idle":"2024-03-11T16:39:44.090490Z","shell.execute_reply":"2024-03-11T16:39:44.089596Z","shell.execute_reply.started":"2024-03-11T16:39:44.081738Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(101)\n","train_loader = DataLoader(train_dataset, batch_size= 64, shuffle = True)\n","test_loader = DataLoader(test_dataset, batch_size= 64)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:39:52.763201Z","iopub.status.busy":"2024-03-11T16:39:52.762782Z","iopub.status.idle":"2024-03-11T16:39:52.799608Z","shell.execute_reply":"2024-03-11T16:39:52.798327Z","shell.execute_reply.started":"2024-03-11T16:39:52.763160Z"},"trusted":true},"outputs":[],"source":["device = get_device()\n","train_loader = ToDeviceLoader(train_loader, device)\n","test_loader = ToDeviceLoader(test_loader, device)"]},{"cell_type":"markdown","metadata":{},"source":["# Patch Embedding"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:40:10.598405Z","iopub.status.busy":"2024-03-11T16:40:10.598016Z","iopub.status.idle":"2024-03-11T16:40:10.605417Z","shell.execute_reply":"2024-03-11T16:40:10.604376Z","shell.execute_reply.started":"2024-03-11T16:40:10.598356Z"},"trusted":true},"outputs":[],"source":["class PatchEmbedding(nn.Module):\n","    def __init__(self, patch_size,emb_size):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        self.emb_size = emb_size\n","    def forward(self,images):\n","        n,c,h,w = images.shape\n","        image = einops.rearrange(images, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = self.patch_size, p2 = self.patch_size)\n","        # image = nn.Linear(self.patch_size * self.patch_size * c, self.emb_size)(image)\n","        return image"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer in ViT"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:40:24.191940Z","iopub.status.busy":"2024-03-11T16:40:24.191543Z","iopub.status.idle":"2024-03-11T16:40:24.200378Z","shell.execute_reply":"2024-03-11T16:40:24.199267Z","shell.execute_reply.started":"2024-03-11T16:40:24.191902Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, emb_dim ,n_heads, drop = 0, ratio_dim = 4):\n","        super().__init__()\n","        self.emb_dim = emb_dim\n","        self.ratio_dim = ratio_dim\n","        self.num_head = n_heads\n","        self.layer_norm1 = nn.LayerNorm(emb_dim)\n","        self.attn = nn.MultiheadAttention(embed_dim= self.emb_dim, num_heads= self.num_head)\n","        self.layer_norm2 = nn.LayerNorm(emb_dim)\n","        self.MLP = nn.Sequential(\n","            nn.Linear(emb_dim, emb_dim * ratio_dim),\n","            nn.GELU(),\n","            nn.Dropout(drop),\n","            nn.Linear(emb_dim * ratio_dim, emb_dim)\n","        )\n","    def forward(self,x):\n","        x = self.layer_norm1(x)\n","        x = x + self.attn(x,x,x)[0]\n","        x = x + self.MLP(self.layer_norm2(x))\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Model ViT"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:42:33.138268Z","iopub.status.busy":"2024-03-11T16:42:33.137267Z","iopub.status.idle":"2024-03-11T16:42:33.150455Z","shell.execute_reply":"2024-03-11T16:42:33.149359Z","shell.execute_reply.started":"2024-03-11T16:42:33.138231Z"},"trusted":true},"outputs":[],"source":["class MyViT(nn.Module):\n","    def __init__(self,n_layer, img_size,patch_size, emb_dim, n_heads, dropout, out_dim):\n","        super().__init__()\n","        self.num_layer = n_layer\n","        self.img_size = img_size\n","        self.patch_size = patch_size\n","        self.embed_dim = emb_dim\n","        self.num_head = n_heads\n","        self.drop = nn.Dropout(dropout)\n","        self.out_dim = out_dim\n","        n_patch = (img_size**2) // (patch_size ** 2)\n","        self.cls_token = nn.Parameter(torch.rand(1,emb_dim))\n","        self.positon = nn.Parameter(torch.rand(n_patch +1, emb_dim))\n","        self.PatchEmbed = PatchEmbedding(patch_size, emb_dim)\n","        self.linear1 = nn.Linear(patch_size * patch_size * 3, emb_dim)\n","        self.transformer = nn.ModuleList([Transformer(emb_dim,n_heads,dropout) for _ in range(n_layer)])\n","        self.linear2 = nn.Linear(emb_dim, out_dim)\n","    def forward(self,x):\n","        n,c,h,w = x.shape\n","        x = self.PatchEmbed(x)\n","        x = self.linear1(x)\n","        x = torch.stack([torch.vstack((self.cls_token, x[i])) for i in range(n)])\n","        z = x + self.positon.repeat(n,1,1)\n","        for block in self.transformer:\n","            z =  block(z)\n","\n","        out = self.linear2(z)\n","        out = out[:,0]\n","        \n","        return out"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:42:36.595663Z","iopub.status.busy":"2024-03-11T16:42:36.595279Z","iopub.status.idle":"2024-03-11T16:42:37.538089Z","shell.execute_reply":"2024-03-11T16:42:37.537113Z","shell.execute_reply.started":"2024-03-11T16:42:36.595632Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["MyViT(\n","  (drop): Dropout(p=0, inplace=False)\n","  (PatchEmbed): PatchEmbedding()\n","  (linear1): Linear(in_features=768, out_features=768, bias=True)\n","  (transformer): ModuleList(\n","    (0-11): 12 x Transformer(\n","      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (MLP): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Dropout(p=0, inplace=False)\n","        (3): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","  )\n","  (linear2): Linear(in_features=768, out_features=6, bias=True)\n",")\n"]}],"source":["model = MyViT(12, 128, 16, 768, 12,0, 6)\n","print(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:43:05.380197Z","iopub.status.busy":"2024-03-11T16:43:05.379218Z","iopub.status.idle":"2024-03-11T16:43:05.660249Z","shell.execute_reply":"2024-03-11T16:43:05.659326Z","shell.execute_reply.started":"2024-03-11T16:43:05.380158Z"},"trusted":true},"outputs":[{"data":{"text/plain":["MyViT(\n","  (drop): Dropout(p=0, inplace=False)\n","  (PatchEmbed): PatchEmbedding()\n","  (linear1): Linear(in_features=768, out_features=768, bias=True)\n","  (transformer): ModuleList(\n","    (0-11): 12 x Transformer(\n","      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attn): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","      )\n","      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (MLP): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Dropout(p=0, inplace=False)\n","        (3): Linear(in_features=3072, out_features=768, bias=True)\n","      )\n","    )\n","  )\n","  (linear2): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model.cuda()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:43:17.953620Z","iopub.status.busy":"2024-03-11T16:43:17.953222Z","iopub.status.idle":"2024-03-11T16:43:17.959713Z","shell.execute_reply":"2024-03-11T16:43:17.958702Z","shell.execute_reply.started":"2024-03-11T16:43:17.953588Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:46:14.854582Z","iopub.status.busy":"2024-03-11T16:46:14.853480Z","iopub.status.idle":"2024-03-11T16:46:14.859108Z","shell.execute_reply":"2024-03-11T16:46:14.857878Z","shell.execute_reply.started":"2024-03-11T16:46:14.854545Z"},"trusted":true},"outputs":[],"source":["epoch = 1"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:43:39.440954Z","iopub.status.busy":"2024-03-11T16:43:39.440571Z","iopub.status.idle":"2024-03-11T16:43:39.445642Z","shell.execute_reply":"2024-03-11T16:43:39.444633Z","shell.execute_reply.started":"2024-03-11T16:43:39.440925Z"},"trusted":true},"outputs":[],"source":["train_epoch_loss = []\n","train_epoch_acc = []\n","test_epoch_loss = []\n","test_epoch_acc = []"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T16:48:10.970454Z","iopub.status.busy":"2024-03-11T16:48:10.970030Z","iopub.status.idle":"2024-03-11T16:49:53.211476Z","shell.execute_reply":"2024-03-11T16:49:53.210510Z","shell.execute_reply.started":"2024-03-11T16:48:10.970403Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","train_loss : 0.0\n","train_accuracy : 99.99999237060547\n","test accuracy: 100.0\n","==================================================\n"]}],"source":["for i in range(epoch):\n","    trn_corr = 0\n","    tst_corr = 0\n","    train_losses = []\n","    train_correct = []\n","    # Run the training batches\n","    for b, (X_train, y_train) in enumerate(train_loader):\n","        y_pred = model(X_train)\n","        loss = criterion(y_pred, y_train)\n","\n","        predicted = torch.max(y_pred.data, 1)[1]\n","        batch_corr = (predicted == y_train).sum()\n","        trn_corr += batch_corr\n","\n","        # Update parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_losses.append(loss.item())\n","\n","    epoch_train_loss = np.mean(train_losses)\n","    train_correct.append(trn_corr)\n","    train_acc = trn_corr/len(train_dataset)\n","    train_epoch_loss.append(epoch_train_loss)\n","    train_epoch_acc.append(train_acc)\n","    \n","\n","    test_corr = 0\n","    for b, (X_test,y_test) in enumerate(test_loader):\n","      y_pred = model(X_test)\n","      predicted = torch.max(y_pred.data, 1)[1]\n","      batch_corr = (predicted == y_test).sum()\n","      test_corr += batch_corr\n","    test_acc = test_corr/len(test_dataset)\n","    test_epoch_acc.append(test_acc)\n","    print(f'Epoch {i+1}')\n","    print(f'train_loss : {epoch_train_loss}')\n","    print(f'train_accuracy : {train_acc*100}')\n","    print(f'test accuracy: {test_acc*100}')\n","    print(25*'==')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
